{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f965746",
   "metadata": {
    "id": "8f965746"
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98da782e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98da782e",
    "outputId": "283f391c-c61f-486e-b462-ba3d028fe073"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\apfle\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\apfle\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download punctuation and stopwords from nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c503a564",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "c503a564",
    "outputId": "9f657eba-8cc5-437c-c6d8-a28b8330ecf1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "0      cb774db0d1                I`d have responded, if I were going   \n",
       "1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2      088c60f138                          my boss is bullying me...   \n",
       "3      9642c003ef                     what interview! leave me alone   \n",
       "4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "...           ...                                                ...   \n",
       "27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
       "27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
       "27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
       "27479  ed167662a5                         But it was worth it  ****.   \n",
       "27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
       "\n",
       "                                           selected_text sentiment  \n",
       "0                    I`d have responded, if I were going   neutral  \n",
       "1                                               Sooo SAD  negative  \n",
       "2                                            bullying me  negative  \n",
       "3                                         leave me alone  negative  \n",
       "4                                          Sons of ****,  negative  \n",
       "...                                                  ...       ...  \n",
       "27476                                             d lost  negative  \n",
       "27477                                      , don`t force  negative  \n",
       "27478                          Yay good for both of you.  positive  \n",
       "27479                         But it was worth it  ****.  positive  \n",
       "27480  All this flirting going on - The ATG smiles. Y...   neutral  \n",
       "\n",
       "[27481 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load tweets_df and view\n",
    "tweets_df = pd.read_csv(\"Resources/Tweets.csv\")\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c311757b",
   "metadata": {
    "id": "c311757b"
   },
   "outputs": [],
   "source": [
    "# get dataframe ready for processing\n",
    "\n",
    "# make sure the tweets in column \"text\" are strings\n",
    "tweets_df['text'] = tweets_df['text'].astype('str')\n",
    "\n",
    "# delete the unneccessary columns\n",
    "tweets_df = tweets_df.drop(columns=[\"textID\", \"selected_text\"])\n",
    "tweets_df=tweets_df.rename(columns={'sentiment':'class'})\n",
    "tweets_df=tweets_df[['class','text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47021da3",
   "metadata": {
    "id": "47021da3"
   },
   "outputs": [],
   "source": [
    "def process_tweets(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    final_tweet = \"\".join(char for char in tweet if char not in string.punctuation)\n",
    "    # tokenize_tweet = word_tokenize(tweet)\n",
    "    # stopword = stopwords.words(\"english\")\n",
    "    # tweet_wo_stop = [word for word in tokenize_tweet if word not in stopword]\n",
    "    # final_tweet = \" \".join(tweet_wo_stop)\n",
    "    return final_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8616da88",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "8616da88",
    "outputId": "a1a0c46a-f186-4926-9ce3-ef59c99a320c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>sons of  why couldnt they put them on the rel...</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>negative</td>\n",
       "      <td>wish we could come see u on denver  husband l...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>negative</td>\n",
       "      <td>ive wondered about rake to  the client has ma...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>positive</td>\n",
       "      <td>yay good for both of you enjoy the break  you...</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>positive</td>\n",
       "      <td>but it was worth it</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>neutral</td>\n",
       "      <td>all this flirting going on  the atg smiles ...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          class                                               text length\n",
       "0       neutral                  id have responded if i were going     34\n",
       "1      negative         sooo sad i will miss you here in san diego     43\n",
       "2      negative                             my boss is bullying me     22\n",
       "3      negative                      what interview leave me alone     30\n",
       "4      negative   sons of  why couldnt they put them on the rel...     69\n",
       "...         ...                                                ...    ...\n",
       "27476  negative   wish we could come see u on denver  husband l...     76\n",
       "27477  negative   ive wondered about rake to  the client has ma...    115\n",
       "27478  positive   yay good for both of you enjoy the break  you...    109\n",
       "27479  positive                              but it was worth it       22\n",
       "27480   neutral     all this flirting going on  the atg smiles ...     55\n",
       "\n",
       "[27481 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # process tweets using above function\n",
    "tweets_df['text'] = tweets_df['text'].apply(lambda x: process_tweets(x))\n",
    "\n",
    "tweets_df['length']=\"\"\n",
    "for index,row in tweets_df.iterrows():\n",
    "  tweet_length=len(row['text'])\n",
    "  tweets_df.loc[index,'length']=tweet_length\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "S9MXQLDf-uYS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S9MXQLDf-uYS",
    "outputId": "7c90203e-b2f7-4149-87f5-3e81e29598f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "The system cannot find the path specified.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "tar: $SPARK_VERSION-bin-hadoop2.7.tgz: Cannot open: No such file or directory\n",
      "tar: Error is not recoverable: exiting now\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Unable to find py4j in /content/spark-3.2.3-bin-hadoop2.7\\python, your SPARK_HOME may not be configured correctly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\findspark.py:159\u001b[0m, in \u001b[0;36minit\u001b[1;34m(spark_home, python_path, edit_rc, edit_profile)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     py4j \u001b[38;5;241m=\u001b[39m \u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspark_python\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpy4j-*.zip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Start a SparkSession\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfindspark\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mfindspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\findspark.py:161\u001b[0m, in \u001b[0;36minit\u001b[1;34m(spark_home, python_path, edit_rc, edit_profile)\u001b[0m\n\u001b[0;32m    159\u001b[0m         py4j \u001b[38;5;241m=\u001b[39m glob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(spark_python, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlib\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpy4j-*.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find py4j in \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, your SPARK_HOME may not be configured correctly\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    163\u001b[0m                 spark_python\n\u001b[0;32m    164\u001b[0m             )\n\u001b[0;32m    165\u001b[0m         )\n\u001b[0;32m    166\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath[:\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m sys_path \u001b[38;5;241m=\u001b[39m [spark_python, py4j]\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# already imported, no need to patch sys.path\u001b[39;00m\n",
      "\u001b[1;31mException\u001b[0m: Unable to find py4j in /content/spark-3.2.3-bin-hadoop2.7\\python, your SPARK_HOME may not be configured correctly"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Find the latest version of spark 3.2  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
    "# For example:\n",
    "spark_version = 'spark-3.2.3'\n",
    "# spark_version = 'spark-3.<enter version>'\n",
    "os.environ['SPARK_VERSION']=spark_version\n",
    "\n",
    "# Install Spark and Java\n",
    "!apt-get update\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
    "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "# Set Environment Variables\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
    "\n",
    "# Start a SparkSession\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xbGse5B0-90I",
   "metadata": {
    "id": "xbGse5B0-90I"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"NaiveBayes\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oAa9oOV6-96p",
   "metadata": {
    "id": "oAa9oOV6-96p"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
    "# Create all the features to the data set\n",
    "pos_neg_to_num = StringIndexer(inputCol='class',outputCol='label')\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")\n",
    "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
    "hashingTF = HashingTF(inputCol=\"stop_tokens\", outputCol='hash_token')\n",
    "idf = IDF(inputCol='hash_token', outputCol='idf_token')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hp-Q2rQs--AX",
   "metadata": {
    "id": "hp-Q2rQs--AX"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector\n",
    "\n",
    "# Create feature vectors\n",
    "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gnEhOMkx--Fs",
   "metadata": {
    "id": "gnEhOMkx--Fs"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "data_prep_pipeline = Pipeline(stages=[pos_neg_to_num, tokenizer, stopremove, hashingTF, idf, clean_up])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8GdSYbADBTUQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8GdSYbADBTUQ",
    "outputId": "62322767-0fcc-4afa-ea87-ce854a65d463"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sc = SparkSession.builder.getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "spark_tweets = sqlContext.createDataFrame(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QmvaA37y--Lg",
   "metadata": {
    "id": "QmvaA37y--Lg"
   },
   "outputs": [],
   "source": [
    "cleaner = data_prep_pipeline.fit(spark_tweets)\n",
    "cleaned = cleaner.transform(spark_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QP5P_wgp--Re",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QP5P_wgp--Re",
    "outputId": "3f221437-dd6b-4811-d082-1507ec932a0e"
   },
   "outputs": [],
   "source": [
    "# Show label and resulting features\n",
    "cleaned.select(['label', 'features']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0EQutHPI--Xf",
   "metadata": {
    "id": "0EQutHPI--Xf"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "# Break data down into a training set and a testing set\n",
    "training, testing = cleaned.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Create a Naive Bayes model and fit training data\n",
    "nb = NaiveBayes()\n",
    "predictor = nb.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olakwIuXB0AG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "olakwIuXB0AG",
    "outputId": "b7a84a62-edbc-4db6-eb6a-cbb39142163a"
   },
   "outputs": [],
   "source": [
    "# Tranform the model with the testing data\n",
    "test_results = predictor.transform(testing)\n",
    "test_results.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i7ykfOtTB1Ov",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i7ykfOtTB1Ov",
    "outputId": "db2b19d1-5f44-4205-cda5-9712e20f7413"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "acc_eval = MulticlassClassificationEvaluator()\n",
    "acc = acc_eval.evaluate(test_results)\n",
    "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rGKVlWynu0DD",
   "metadata": {
    "id": "rGKVlWynu0DD"
   },
   "source": [
    "Optimized - Removing tweets marked as 'neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hay5Ep11BzI5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Hay5Ep11BzI5",
    "outputId": "915a2c80-2a71-4b39-a6a0-143e9d012964"
   },
   "outputs": [],
   "source": [
    "optimized_df = pd.read_csv(\"/content/Tweets.csv\")\n",
    "optimized_df=optimized_df.loc[optimized_df['sentiment']!=\"neutral\"]\n",
    "optimized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5vscnf2TvCxe",
   "metadata": {
    "id": "5vscnf2TvCxe"
   },
   "outputs": [],
   "source": [
    "# get dataframe ready for processing\n",
    "\n",
    "# make sure the tweets in column \"text\" are strings\n",
    "optimized_df['text'] = optimized_df['text'].astype('str')\n",
    "\n",
    "# delete the unneccessary columns\n",
    "optimized_df = optimized_df.drop(columns=[\"textID\", \"selected_text\"])\n",
    "optimized_df=optimized_df.rename(columns={'sentiment':'class'})\n",
    "optimized_df=optimized_df[['class','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vic8U2jkvIeU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Vic8U2jkvIeU",
    "outputId": "e0785978-a3ba-4e4c-c485-7062eea88c9c"
   },
   "outputs": [],
   "source": [
    "optimized_df['text'] = optimized_df['text'].apply(lambda x: process_tweets(x))\n",
    "optimized_df['length']=\"\"\n",
    "for index,row in optimized_df.iterrows():\n",
    "  tweet_length=len(row['text'])\n",
    "  optimized_df.loc[index,'length']=tweet_length\n",
    "optimized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7GnRbGyjvIj2",
   "metadata": {
    "id": "7GnRbGyjvIj2"
   },
   "outputs": [],
   "source": [
    "\n",
    "opt_spark_tweets = sqlContext.createDataFrame(optimized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ir6nyI-gvIoB",
   "metadata": {
    "id": "ir6nyI-gvIoB"
   },
   "outputs": [],
   "source": [
    "cleaner = data_prep_pipeline.fit(opt_spark_tweets)\n",
    "cleaned = cleaner.transform(opt_spark_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vFa_G1F5vIq3",
   "metadata": {
    "id": "vFa_G1F5vIq3"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "# Break data down into a training set and a testing set\n",
    "training, testing = cleaned.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Create a Naive Bayes model and fit training data\n",
    "opt_nb = NaiveBayes()\n",
    "opt_predictor = opt_nb.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ICsPpHbvItd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ICsPpHbvItd",
    "outputId": "5c02d8f6-11a8-4518-a160-d86b955bf2dc"
   },
   "outputs": [],
   "source": [
    "opt_test_results = opt_predictor.transform(testing)\n",
    "opt_test_results.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yKNLhHr3vIwE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yKNLhHr3vIwE",
    "outputId": "f512d964-5743-42cb-c411-9011d4543990"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "acc_eval = MulticlassClassificationEvaluator()\n",
    "acc = acc_eval.evaluate(test_results)\n",
    "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5NqD0kZgvIyq",
   "metadata": {
    "id": "5NqD0kZgvIyq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_fF96lQBvI1U",
   "metadata": {
    "id": "_fF96lQBvI1U"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hu1Up4iLvI3_",
   "metadata": {
    "id": "hu1Up4iLvI3_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5RDxPBSvI61",
   "metadata": {
    "id": "c5RDxPBSvI61"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ANXUpQIOvI-U",
   "metadata": {
    "id": "ANXUpQIOvI-U"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
